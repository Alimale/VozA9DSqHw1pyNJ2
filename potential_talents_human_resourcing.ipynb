{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f1fc82",
   "metadata": {},
   "source": [
    "### Data Description:\n",
    "\n",
    "The data comes from our sourcing efforts. We removed any field that could directly reveal personal details and gave a unique identifier for each candidate.\n",
    "\n",
    "Attributes:\n",
    "id : unique identifier for candidate (numeric)\n",
    "job_title : job title for candidate (text)\n",
    "location : geographical location for candidate (text)\n",
    "connections: number of connections candidate has, 500+ means over 500 (text)\n",
    "Output (desired target):\n",
    "fit - how fit the candidate is for the role? (numeric, probability between 0-1)\n",
    "Keywords: “Aspiring human resources” or “seeking human resources”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a765ac5",
   "metadata": {},
   "source": [
    "### Project description:\n",
    "Assuming that we were able to list and rank fitting candidates, we then employ a review procedure, as each candidate needs to be reviewed and then determined how good a fit they are through manual inspection. This procedure is done manually and at the end of this manual review, we might choose not the first fitting candidate in the list but maybe the 7th candidate in the list. If that happens, we are interested in being able to re-rank the previous list based on this information. This supervisory signal is going to be supplied by starring the 7th candidate in the list. Starring one candidate actually sets this candidate as an ideal candidate for the given role. Then, we expect the list to be re-ranked each time a candidate is starred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9373682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9b7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\potential-talents - Aspiring human resources - seeking human resources.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0273b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>Lake Forest, California</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>SVP, CHRO, Marketing &amp; Communications, CSR Off...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Human Resources Coordinator at InterContinenta...</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0    1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1    2  Native English Teacher at EPIK (English Progra...   \n",
       "2    3              Aspiring Human Resources Professional   \n",
       "3    4             People Development Coordinator at Ryan   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "5    6                Aspiring Human Resources Specialist   \n",
       "6    7  Student at Humber College and Aspiring Human R...   \n",
       "7    8                               HR Senior Specialist   \n",
       "8    9  Student at Humber College and Aspiring Human R...   \n",
       "9   10  Seeking Human Resources HRIS and Generalist Po...   \n",
       "10  11                      Student at Chapman University   \n",
       "11  12  SVP, CHRO, Marketing & Communications, CSR Off...   \n",
       "12  13  Human Resources Coordinator at InterContinenta...   \n",
       "13  14  2019 C.T. Bauer College of Business Graduate (...   \n",
       "14  15  2019 C.T. Bauer College of Business Graduate (...   \n",
       "15  16  Native English Teacher at EPIK (English Progra...   \n",
       "16  17              Aspiring Human Resources Professional   \n",
       "17  18             People Development Coordinator at Ryan   \n",
       "18  19  2019 C.T. Bauer College of Business Graduate (...   \n",
       "19  20  Native English Teacher at EPIK (English Progra...   \n",
       "20  21              Aspiring Human Resources Professional   \n",
       "21  22             People Development Coordinator at Ryan   \n",
       "22  23    Advisory Board Member at Celal Bayar University   \n",
       "23  24                Aspiring Human Resources Specialist   \n",
       "24  25  Student at Humber College and Aspiring Human R...   \n",
       "25  26                               HR Senior Specialist   \n",
       "26  27  Aspiring Human Resources Management student se...   \n",
       "27  28              Seeking Human Resources Opportunities   \n",
       "28  29  Aspiring Human Resources Management student se...   \n",
       "29  30              Seeking Human Resources Opportunities   \n",
       "30  31  2019 C.T. Bauer College of Business Graduate (...   \n",
       "31  32  Native English Teacher at EPIK (English Progra...   \n",
       "32  33              Aspiring Human Resources Professional   \n",
       "33  34             People Development Coordinator at Ryan   \n",
       "34  35    Advisory Board Member at Celal Bayar University   \n",
       "35  36                Aspiring Human Resources Specialist   \n",
       "36  37  Student at Humber College and Aspiring Human R...   \n",
       "37  38                               HR Senior Specialist   \n",
       "38  39  Student at Humber College and Aspiring Human R...   \n",
       "39  40  Seeking Human Resources HRIS and Generalist Po...   \n",
       "\n",
       "                               location connection  fit  \n",
       "0                        Houston, Texas         85  NaN  \n",
       "1                                Kanada      500+   NaN  \n",
       "2   Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                         Denton, Texas      500+   NaN  \n",
       "4                        İzmir, Türkiye      500+   NaN  \n",
       "5            Greater New York City Area          1  NaN  \n",
       "6                                Kanada         61  NaN  \n",
       "7                San Francisco Bay Area      500+   NaN  \n",
       "8                                Kanada         61  NaN  \n",
       "9             Greater Philadelphia Area      500+   NaN  \n",
       "10              Lake Forest, California          2  NaN  \n",
       "11                  Houston, Texas Area      500+   NaN  \n",
       "12                     Atlanta, Georgia      500+   NaN  \n",
       "13                       Houston, Texas         85  NaN  \n",
       "14                       Houston, Texas         85  NaN  \n",
       "15                               Kanada      500+   NaN  \n",
       "16  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "17                        Denton, Texas      500+   NaN  \n",
       "18                       Houston, Texas         85  NaN  \n",
       "19                               Kanada      500+   NaN  \n",
       "20  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "21                        Denton, Texas      500+   NaN  \n",
       "22                       İzmir, Türkiye      500+   NaN  \n",
       "23           Greater New York City Area          1  NaN  \n",
       "24                               Kanada         61  NaN  \n",
       "25               San Francisco Bay Area      500+   NaN  \n",
       "26                  Houston, Texas Area      500+   NaN  \n",
       "27                    Chicago, Illinois        390  NaN  \n",
       "28                  Houston, Texas Area      500+   NaN  \n",
       "29                    Chicago, Illinois        390  NaN  \n",
       "30                       Houston, Texas         85  NaN  \n",
       "31                               Kanada      500+   NaN  \n",
       "32  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "33                        Denton, Texas      500+   NaN  \n",
       "34                       İzmir, Türkiye      500+   NaN  \n",
       "35           Greater New York City Area          1  NaN  \n",
       "36                               Kanada         61  NaN  \n",
       "37               San Francisco Bay Area      500+   NaN  \n",
       "38                               Kanada         61  NaN  \n",
       "39            Greater Philadelphia Area      500+   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c825fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003bb26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit\n",
       "count  104.000000  0.0\n",
       "mean    52.500000  NaN\n",
       "std     30.166206  NaN\n",
       "min      1.000000  NaN\n",
       "25%     26.750000  NaN\n",
       "50%     52.500000  NaN\n",
       "75%     78.250000  NaN\n",
       "max    104.000000  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb1ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fec36bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\alima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524705be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "job_title       0\n",
       "location        0\n",
       "connection      0\n",
       "fit           104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43d3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('fit', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae9b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_title'] = df['job_title'].astype(str).str.lower()\n",
    "df['locaiton'] = df['location'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81148292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### to check if there are any empty string with only spaces! \n",
    "df['job_title'].str.isspace().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601a2ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].str.isspace().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e2df1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019 c.t. bauer college of business graduate (magna cum laude) and aspiring human resources professional                 7\n",
       "aspiring human resources professional                                                                                    7\n",
       "student at humber college and aspiring human resources generalist                                                        7\n",
       "people development coordinator at ryan                                                                                   6\n",
       "native english teacher at epik (english program in korea)                                                                5\n",
       "aspiring human resources specialist                                                                                      5\n",
       "hr senior specialist                                                                                                     5\n",
       "student at chapman university                                                                                            4\n",
       "svp, chro, marketing & communications, csr officer | engie | houston | the woodlands | energy | gphr | sphr              4\n",
       "human resources coordinator at intercontinental buckhead atlanta                                                         4\n",
       "seeking human resources hris and generalist positions                                                                    4\n",
       "advisory board member at celal bayar university                                                                          4\n",
       "aspiring human resources management student seeking an internship                                                        2\n",
       "seeking human resources opportunities                                                                                    2\n",
       "seeking human  resources opportunities. open to travel and relocation.                                                   1\n",
       "bachelor of science in biology from victoria university of wellington                                                    1\n",
       "human resources management major                                                                                         1\n",
       "director human resources  at ey                                                                                          1\n",
       "undergraduate research assistant at styczynski lab                                                                       1\n",
       "lead official at western illinois university                                                                             1\n",
       "seeking employment opportunities within customer service or patient care                                                 1\n",
       "admissions representative at community medical center long beach                                                         1\n",
       "human resources generalist at loparex                                                                                    1\n",
       "student at westfield state university                                                                                    1\n",
       "student at indiana university kokomo - business management - \\nretail manager at delphi hardware and paint               1\n",
       "student                                                                                                                  1\n",
       "seeking human resources position                                                                                         1\n",
       "aspiring human resources manager | graduating may 2020 | seeking an entry-level human resources position in st. louis    1\n",
       "rrp brand portfolio executive at jti (japan tobacco international)                                                       1\n",
       "business intelligence and analytics at travelers                                                                         1\n",
       "always set them up for success                                                                                           1\n",
       "information systems specialist and programmer with a love for data and organization.                                     1\n",
       "human resources generalist at schwan's                                                                                   1\n",
       "human resources professional for the world leader in gis software                                                        1\n",
       "aspiring human resources manager, seeking internship in human resources.                                                 1\n",
       "experienced retail manager and aspiring human resources professional                                                     1\n",
       "human resources, staffing and recruiting professional                                                                    1\n",
       "human resources specialist at luxottica                                                                                  1\n",
       "director of human resources north america, groupe beneteau                                                               1\n",
       "retired army national guard recruiter, office manager,  seeking a position in human resources.                           1\n",
       "human resources generalist at scottmadden, inc.                                                                          1\n",
       "business management major and aspiring human resources manager                                                           1\n",
       "human resources professional                                                                                             1\n",
       "hr manager at endemol shine north america                                                                                1\n",
       "nortia staffing is seeking human resources, payroll & administrative professionals!!  (408) 709-2621                     1\n",
       "aspiring human resources professional | passionate about helping to create an inclusive and engaging work environment    1\n",
       "human resources|\\nconflict management|\\npolicies & procedures|talent management|benefits & compensation                  1\n",
       "liberal arts major. aspiring human resources analyst.                                                                    1\n",
       "junior mes engineer| information systems                                                                                 1\n",
       "senior human resources business partner at heil environmental                                                            1\n",
       "aspiring human resources professional | an energetic and team-focused leader                                             1\n",
       "director of administration at excellence logging                                                                         1\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb655382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b936535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9875665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuation\n",
    "df['job_title'] = df['job_title'].apply(lambda text: ''.join([char for char in text if char not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289170f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing!\n",
    "df['preprocessed_job_titles'] = df['job_title'].apply(lambda title: word_tokenize(title)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f071f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words!\n",
    "stop_words = set(stopwords.words('english'))\n",
    "remove_stopwords = lambda tokens: [token for token in tokens if token.lower() not in stop_words]\n",
    "df['preprocessed_job_titles'] = df['preprocessed_job_titles'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad31e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming!\n",
    "stemmer = PorterStemmer()\n",
    "df['preprocessed_job_titles'] = df['preprocessed_job_titles'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "941cc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the tokens!\n",
    "df['preprocessed_job_titles'] = df['preprocessed_job_titles'].apply(lambda title: ' '.join(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df4708d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2019 ct bauer colleg busi graduat magna cum la...\n",
       "1       nativ english teacher epik english program korea\n",
       "2                         aspir human resourc profession\n",
       "3                             peopl develop coordin ryan\n",
       "4              advisori board member celal bayar univers\n",
       "                             ...                        \n",
       "99     aspir human resourc manag graduat may 2020 see...\n",
       "100                     human resourc generalist loparex\n",
       "101                          busi intellig analyt travel\n",
       "102                                    alway set success\n",
       "103                         director administr excel log\n",
       "Name: preprocessed_job_titles, Length: 104, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_job_titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d99f932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student humber colleg aspir human resourc generalist']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_job_title = [df['preprocessed_job_titles'][6]]\n",
    "reference_job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ced2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['preprocessed_job_titles'])\n",
    "tfidf_reference_title = vectorizer.transform(reference_job_title)\n",
    "cosine_similarities = cosine_similarity(tfidf_reference_title, tfidf_matrix).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b77d589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_score'] = cosine_similarities\n",
    "df_sorted = df.sort_values(by='similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b511b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>locaiton</th>\n",
       "      <th>preprocessed_job_titles</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>student</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>4</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>student</td>\n",
       "      <td>0.411275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>aspir human resourc manag student seek internship</td>\n",
       "      <td>0.337110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>aspiring human resources management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>aspir human resourc manag student seek internship</td>\n",
       "      <td>0.337110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>kokomo, indiana area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.331234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>human resources generalist at loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>human resourc generalist loparex</td>\n",
       "      <td>0.315748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>human resources generalist at schwans</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>500+</td>\n",
       "      <td>amerika birleşik devletleri</td>\n",
       "      <td>human resourc generalist schwan</td>\n",
       "      <td>0.315748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>aspiring human resources specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.303436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          job_title  \\\n",
       "49    50  student at humber college and aspiring human r...   \n",
       "51    52  student at humber college and aspiring human r...   \n",
       "36    37  student at humber college and aspiring human r...   \n",
       "6      7  student at humber college and aspiring human r...   \n",
       "8      9  student at humber college and aspiring human r...   \n",
       "38    39  student at humber college and aspiring human r...   \n",
       "24    25  student at humber college and aspiring human r...   \n",
       "97    98                                            student   \n",
       "28    29  aspiring human resources management student se...   \n",
       "26    27  aspiring human resources management student se...   \n",
       "16    17              aspiring human resources professional   \n",
       "57    58              aspiring human resources professional   \n",
       "45    46              aspiring human resources professional   \n",
       "32    33              aspiring human resources professional   \n",
       "20    21              aspiring human resources professional   \n",
       "96    97              aspiring human resources professional   \n",
       "2      3              aspiring human resources professional   \n",
       "100  101              human resources generalist at loparex   \n",
       "77    78              human resources generalist at schwans   \n",
       "23    24                aspiring human resources specialist   \n",
       "\n",
       "                                location connection  \\\n",
       "49                                Kanada         61   \n",
       "51                                Kanada         61   \n",
       "36                                Kanada         61   \n",
       "6                                 Kanada         61   \n",
       "8                                 Kanada         61   \n",
       "38                                Kanada         61   \n",
       "24                                Kanada         61   \n",
       "97                   Houston, Texas Area          4   \n",
       "28                   Houston, Texas Area      500+    \n",
       "26                   Houston, Texas Area      500+    \n",
       "16   Raleigh-Durham, North Carolina Area         44   \n",
       "57   Raleigh-Durham, North Carolina Area         44   \n",
       "45   Raleigh-Durham, North Carolina Area         44   \n",
       "32   Raleigh-Durham, North Carolina Area         44   \n",
       "20   Raleigh-Durham, North Carolina Area         44   \n",
       "96                  Kokomo, Indiana Area         71   \n",
       "2    Raleigh-Durham, North Carolina Area         44   \n",
       "100  Raleigh-Durham, North Carolina Area      500+    \n",
       "77           Amerika Birleşik Devletleri      500+    \n",
       "23            Greater New York City Area          1   \n",
       "\n",
       "                                locaiton  \\\n",
       "49                                kanada   \n",
       "51                                kanada   \n",
       "36                                kanada   \n",
       "6                                 kanada   \n",
       "8                                 kanada   \n",
       "38                                kanada   \n",
       "24                                kanada   \n",
       "97                   houston, texas area   \n",
       "28                   houston, texas area   \n",
       "26                   houston, texas area   \n",
       "16   raleigh-durham, north carolina area   \n",
       "57   raleigh-durham, north carolina area   \n",
       "45   raleigh-durham, north carolina area   \n",
       "32   raleigh-durham, north carolina area   \n",
       "20   raleigh-durham, north carolina area   \n",
       "96                  kokomo, indiana area   \n",
       "2    raleigh-durham, north carolina area   \n",
       "100  raleigh-durham, north carolina area   \n",
       "77           amerika birleşik devletleri   \n",
       "23            greater new york city area   \n",
       "\n",
       "                               preprocessed_job_titles  similarity_score  \n",
       "49   student humber colleg aspir human resourc gene...          1.000000  \n",
       "51   student humber colleg aspir human resourc gene...          1.000000  \n",
       "36   student humber colleg aspir human resourc gene...          1.000000  \n",
       "6    student humber colleg aspir human resourc gene...          1.000000  \n",
       "8    student humber colleg aspir human resourc gene...          1.000000  \n",
       "38   student humber colleg aspir human resourc gene...          1.000000  \n",
       "24   student humber colleg aspir human resourc gene...          1.000000  \n",
       "97                                             student          0.411275  \n",
       "28   aspir human resourc manag student seek internship          0.337110  \n",
       "26   aspir human resourc manag student seek internship          0.337110  \n",
       "16                      aspir human resourc profession          0.331234  \n",
       "57                      aspir human resourc profession          0.331234  \n",
       "45                      aspir human resourc profession          0.331234  \n",
       "32                      aspir human resourc profession          0.331234  \n",
       "20                      aspir human resourc profession          0.331234  \n",
       "96                      aspir human resourc profession          0.331234  \n",
       "2                       aspir human resourc profession          0.331234  \n",
       "100                   human resourc generalist loparex          0.315748  \n",
       "77                     human resourc generalist schwan          0.315748  \n",
       "23                      aspir human resourc specialist          0.303436  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6dfb6e",
   "metadata": {},
   "source": [
    "## Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0707abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from en-core-web-md==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.22.4)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (61.2.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\alima\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (6.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7836a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eaf6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation\n",
    "def preprocess_text(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_title'] = df['job_title'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5fc6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_text = df[\"job_title\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cb339e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(text1, text2):\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    vec1 = doc1.vector.reshape(1, -1)\n",
    "    vec2 = doc2.vector.reshape(1, -1)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9a5f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_score'] = df['job_title'].apply(lambda x: calculate_similarity(x, reference_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c2bb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b79d0cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>locaiton</th>\n",
       "      <th>preprocessed_job_titles</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>12</td>\n",
       "      <td>svp chro marketing  communications csr officer...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>svp chro market commun csr offic engi houston ...</td>\n",
       "      <td>0.615281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>55</td>\n",
       "      <td>svp chro marketing  communications csr officer...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>svp chro market commun csr offic engi houston ...</td>\n",
       "      <td>0.615281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>64</td>\n",
       "      <td>svp chro marketing  communications csr officer...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>houston, texas area</td>\n",
       "      <td>svp chro market commun csr offic engi houston ...</td>\n",
       "      <td>0.615281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>85</td>\n",
       "      <td>rrp brand portfolio executive at jti japan tob...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>greater philadelphia area</td>\n",
       "      <td>rrp brand portfolio execut jti japan tobacco i...</td>\n",
       "      <td>0.610477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>83</td>\n",
       "      <td>hr manager at endemol shine north america</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>268</td>\n",
       "      <td>los angeles, california</td>\n",
       "      <td>hr manag endemol shine north america</td>\n",
       "      <td>0.534341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "0    25  student at humber college and aspiring human r...   \n",
       "1    37  student at humber college and aspiring human r...   \n",
       "2     7  student at humber college and aspiring human r...   \n",
       "3    39  student at humber college and aspiring human r...   \n",
       "4     9  student at humber college and aspiring human r...   \n",
       "..   ..                                                ...   \n",
       "99   12  svp chro marketing  communications csr officer...   \n",
       "100  55  svp chro marketing  communications csr officer...   \n",
       "101  64  svp chro marketing  communications csr officer...   \n",
       "102  85  rrp brand portfolio executive at jti japan tob...   \n",
       "103  83          hr manager at endemol shine north america   \n",
       "\n",
       "                      location connection                   locaiton  \\\n",
       "0                       Kanada         61                     kanada   \n",
       "1                       Kanada         61                     kanada   \n",
       "2                       Kanada         61                     kanada   \n",
       "3                       Kanada         61                     kanada   \n",
       "4                       Kanada         61                     kanada   \n",
       "..                         ...        ...                        ...   \n",
       "99         Houston, Texas Area      500+         houston, texas area   \n",
       "100        Houston, Texas Area      500+         houston, texas area   \n",
       "101        Houston, Texas Area      500+         houston, texas area   \n",
       "102  Greater Philadelphia Area      500+   greater philadelphia area   \n",
       "103    Los Angeles, California        268    los angeles, california   \n",
       "\n",
       "                               preprocessed_job_titles  similarity_score  \n",
       "0    student humber colleg aspir human resourc gene...          1.000000  \n",
       "1    student humber colleg aspir human resourc gene...          1.000000  \n",
       "2    student humber colleg aspir human resourc gene...          1.000000  \n",
       "3    student humber colleg aspir human resourc gene...          1.000000  \n",
       "4    student humber colleg aspir human resourc gene...          1.000000  \n",
       "..                                                 ...               ...  \n",
       "99   svp chro market commun csr offic engi houston ...          0.615281  \n",
       "100  svp chro market commun csr offic engi houston ...          0.615281  \n",
       "101  svp chro market commun csr offic engi houston ...          0.615281  \n",
       "102  rrp brand portfolio execut jti japan tobacco i...          0.610477  \n",
       "103               hr manag endemol shine north america          0.534341  \n",
       "\n",
       "[104 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1810c6",
   "metadata": {},
   "source": [
    "## Transformers Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d727a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\alima\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\alima\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\alima\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\alima\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alima\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-win_amd64.whl (266 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\alima\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\alima\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\alima\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125940 sha256=eac945e22747228a66ca6956be9e33a03630ed461b94ec9ef96888923d756483\n",
      "  Stored in directory: c:\\users\\alima\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: numpy, tokenizers, safetensors, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "555e6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f943f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbec24dce9d949bca6453a6e171e2241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8af3ee4b45d47e18afed7459d820ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4f63fc10984e3793da369ed35a8061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/README.md:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710e19ce15984890abc2c9ca0e1eba70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d1/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7902ee3bbbf4ff4b9c307b92ce11cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)01e821d1/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d9a39dbab466faa12565f9407fde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973d139771374c4a8de3dd5bbfafa522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a1d14c4d1d4912b9bee9af49423d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fd80aab34b4f42b0de18cf00cf8f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e01f5060514894a52ac20eb10368df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f1f073965e4a589661457b80724567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b251ee5d59480098a034a2f6b0a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd8219107a84a92b387a50ff97622df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1e821d1/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbcf1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(df['job_title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "980233c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformers_similarity(text1, text2):\n",
    "    emb1 = model.encode(text1).reshape(1,-1)\n",
    "    emb2 = model.encode(text2).reshape(1,-1)\n",
    "    return cosine_similarity(emb1, emb2)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8712aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_score = util.pytorch_cos_sim(embeddings, embeddings[6])\n",
    "reference_text = df[\"job_title\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d94f48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_score'] = df['job_title'].apply(lambda x: transformers_similarity(x, reference_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed630645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2689c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>locaiton</th>\n",
       "      <th>preprocessed_job_titles</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>kanada</td>\n",
       "      <td>student humber colleg aspir human resourc gene...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>77</td>\n",
       "      <td>human resources\\nconflict management\\npolicies...</td>\n",
       "      <td>Dallas/Fort Worth Area</td>\n",
       "      <td>409</td>\n",
       "      <td>dallas/fort worth area</td>\n",
       "      <td>human resourc conflict manag polici procedures...</td>\n",
       "      <td>0.446264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>103</td>\n",
       "      <td>always set them up for success</td>\n",
       "      <td>Greater Los Angeles Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>greater los angeles area</td>\n",
       "      <td>alway set success</td>\n",
       "      <td>0.422414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>85</td>\n",
       "      <td>rrp brand portfolio executive at jti japan tob...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>greater philadelphia area</td>\n",
       "      <td>rrp brand portfolio execut jti japan tobacco i...</td>\n",
       "      <td>0.403827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>93</td>\n",
       "      <td>admissions representative at community medical...</td>\n",
       "      <td>Long Beach, California</td>\n",
       "      <td>9</td>\n",
       "      <td>long beach, california</td>\n",
       "      <td>admiss repres commun medic center long beach</td>\n",
       "      <td>0.392872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>87</td>\n",
       "      <td>bachelor of science in biology from victoria u...</td>\n",
       "      <td>Baltimore, Maryland</td>\n",
       "      <td>40</td>\n",
       "      <td>baltimore, maryland</td>\n",
       "      <td>bachelor scienc biolog victoria univers wellin...</td>\n",
       "      <td>0.386871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          job_title  \\\n",
       "0     25  student at humber college and aspiring human r...   \n",
       "1      7  student at humber college and aspiring human r...   \n",
       "2     39  student at humber college and aspiring human r...   \n",
       "3      9  student at humber college and aspiring human r...   \n",
       "4     50  student at humber college and aspiring human r...   \n",
       "..   ...                                                ...   \n",
       "99    77  human resources\\nconflict management\\npolicies...   \n",
       "100  103                     always set them up for success   \n",
       "101   85  rrp brand portfolio executive at jti japan tob...   \n",
       "102   93  admissions representative at community medical...   \n",
       "103   87  bachelor of science in biology from victoria u...   \n",
       "\n",
       "                      location connection                   locaiton  \\\n",
       "0                       Kanada         61                     kanada   \n",
       "1                       Kanada         61                     kanada   \n",
       "2                       Kanada         61                     kanada   \n",
       "3                       Kanada         61                     kanada   \n",
       "4                       Kanada         61                     kanada   \n",
       "..                         ...        ...                        ...   \n",
       "99      Dallas/Fort Worth Area        409     dallas/fort worth area   \n",
       "100   Greater Los Angeles Area      500+    greater los angeles area   \n",
       "101  Greater Philadelphia Area      500+   greater philadelphia area   \n",
       "102     Long Beach, California          9     long beach, california   \n",
       "103        Baltimore, Maryland         40        baltimore, maryland   \n",
       "\n",
       "                               preprocessed_job_titles  similarity_score  \n",
       "0    student humber colleg aspir human resourc gene...          1.000000  \n",
       "1    student humber colleg aspir human resourc gene...          1.000000  \n",
       "2    student humber colleg aspir human resourc gene...          1.000000  \n",
       "3    student humber colleg aspir human resourc gene...          1.000000  \n",
       "4    student humber colleg aspir human resourc gene...          1.000000  \n",
       "..                                                 ...               ...  \n",
       "99   human resourc conflict manag polici procedures...          0.446264  \n",
       "100                                  alway set success          0.422414  \n",
       "101  rrp brand portfolio execut jti japan tobacco i...          0.403827  \n",
       "102       admiss repres commun medic center long beach          0.392872  \n",
       "103  bachelor scienc biolog victoria univers wellin...          0.386871  \n",
       "\n",
       "[104 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea0233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf15b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
